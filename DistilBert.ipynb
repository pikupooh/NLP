{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip  install transformers -q"
      ],
      "metadata": {
        "id": "Wh-oEpXWCNfP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import json\n",
        "\n",
        "import transformers\n",
        "\n",
        "\n",
        "from transformers import DistilBertTokenizer\n",
        "# from transformers import TFDistilBertForSequenceClassification\n",
        "from transformers import TextClassificationPipeline\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder,LabelEncoder"
      ],
      "metadata": {
        "id": "AlJ2v7FP9EME"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('generated_data.json') as file:\n",
        "  data = json.loads(file.read())"
      ],
      "metadata": {
        "id": "7tIHPsR--8Y8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data['data']"
      ],
      "metadata": {
        "id": "Wj5rCxpS-88E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data)"
      ],
      "metadata": {
        "id": "AN8sKuaB--7_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame(data, columns = ['phrases', 'intents'])"
      ],
      "metadata": {
        "id": "jy9aKrB1_Fip"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['encoded_intents'] = data['intents'].astype('category').cat.codes"
      ],
      "metadata": {
        "id": "N2laMtY8KOfM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiUArnCnMVo8",
        "outputId": "5343e018-a099-45f1-bdc2-452979bdfb0a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            phrases intents  encoded_intents\n",
            "0                         call alex    call                0\n",
            "1                  please call mark    call                0\n",
            "2               i want to call mark    call                0\n",
            "3                  let me call mark    call                0\n",
            "4                  can we call mark    call                0\n",
            "...                             ...     ...              ...\n",
            "1345       what is the current time    time                2\n",
            "1346        what's the current time    time                2\n",
            "1347  what time is it in california    time                2\n",
            "1348        please give me the time    time                2\n",
            "1349               the time is what    time                2\n",
            "\n",
            "[1350 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_texts = data['phrases'].to_list()\n",
        "\n",
        "data_labels = data['encoded_intents'].to_list()"
      ],
      "metadata": {
        "id": "GJw2Qp6gNXSv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(data_texts, data_labels, test_size = 0.2, random_state = 0 )\n",
        "\n",
        "\n",
        "# train_texts, test_texts, train_labels, test_labels = train_test_split(data_texts, train_labels, test_size = 0.2, random_state = 0 )"
      ],
      "metadata": {
        "id": "lI5-CQOE_TPg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation = True, padding = True, max_length = 500, return_tensors = \"tf\")\n",
        "\n",
        "val_encodings = tokenizer(val_texts, truncation = True, padding = True,  max_length = 500, return_tensors = \"tf\" )\n",
        "\n",
        "# test_encodings = tokenizer(test_texts, truncation = True, padding = True,  max_length = 500 )"
      ],
      "metadata": {
        "id": "hF3WiqKgA9wL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3FyoO5QGL2v",
        "outputId": "1e0491e3-ecc4-47a7-dde6-a158b5f84f91"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(1080, 15), dtype=int32, numpy=\n",
              "array([[  101, 13764,  1060, ...,     0,     0,     0],\n",
              "       [  101,  3531, 13764, ...,     0,     0,     0],\n",
              "       [  101,  2064,  2017, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  101,  2129,  2397, ...,     0,     0,     0],\n",
              "       [  101,  2064,  2017, ...,     0,     0,     0],\n",
              "       [  101,  2173,  1037, ...,     0,     0,     0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1080, 15), dtype=int32, numpy=\n",
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    train_labels\n",
        "))\n",
        "\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(val_encodings),\n",
        "    val_labels\n",
        "))\n",
        "\n",
        "# test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#     dict(test_encodings),\n",
        "#     test_labels\n",
        "# ))"
      ],
      "metadata": {
        "id": "Twsk2RKmCjZi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3kCbCt2ra1e",
        "outputId": "517545b4-955b-457d-993b-a9cb468d7a94"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=({'input_ids': TensorSpec(shape=(15,), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(15,), dtype=tf.int32, name=None)}, TensorSpec(shape=(), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer, TFDistilBertForSequenceClassification\n",
        "\n",
        "training_args = TrainingArguments(output_dir=\"./result\", evaluation_strategy=\"epoch\")\n",
        "\n",
        "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels = 3 )"
      ],
      "metadata": {
        "id": "6KZ-f7d5nefa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33b15237-04cd-4bb0-c04e-b3316b572638"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['activation_13', 'vocab_layer_norm', 'vocab_projector', 'vocab_transform']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_19', 'classifier', 'pre_classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "model.compile(optimizer=optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMMMDh9Woumz",
        "outputId": "bb9a4880-4710-4fdb-b33b-a9110203772d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset.shuffle(100).batch(16),\n",
        "          epochs=3,\n",
        "          batch_size=16,\n",
        "          validation_data=val_dataset.shuffle(100).batch(16))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuu5Y4tK_MGU",
        "outputId": "c987a10e-4d88-4ad6-cfa5-8fff7c768550"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "68/68 [==============================] - 224s 3s/step - loss: 0.4285 - accuracy: 0.8380 - val_loss: 0.1109 - val_accuracy: 0.9704\n",
            "Epoch 2/3\n",
            "68/68 [==============================] - 180s 3s/step - loss: 0.1792 - accuracy: 0.9250 - val_loss: 0.0843 - val_accuracy: 0.9667\n",
            "Epoch 3/3\n",
            "68/68 [==============================] - 177s 3s/step - loss: 0.1466 - accuracy: 0.9361 - val_loss: 0.0790 - val_accuracy: 0.9704\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6bd135a710>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "          \"make a call to rohit\",\n",
        "          \"please text rohit\",\n",
        "          \"get card details\",\n",
        "          \"connect\",\n",
        "          \"send an email to rohit\",\n",
        "          \"help\",\n",
        "          \"call and chat\",\n",
        "          \"chat and call\",\n",
        "          \"email someone\",\n",
        "          \"get time from india\",\n",
        "         \"call rohit\", \n",
        "         \"call and chat\", \n",
        "         \"chat and call\", \n",
        "         \"help\", \n",
        "         \"connect with rohit\", \n",
        "         \"dial rohit\", \n",
        "         \"texting rohit\", \n",
        "         \"make a call and chat\", \n",
        "         \"connect me with helpdesk\",\n",
        "         \"onboard me\"\n",
        "        ]\n",
        "\n",
        "for text in texts:\n",
        "\n",
        "  predict_input = tokenizer.encode(text,\n",
        "                                  truncation=True,\n",
        "                                  padding=True,\n",
        "                                  return_tensors=\"tf\")\n",
        "  tf_output = model.predict(predict_input)[0]\n",
        "  print(text)\n",
        "  print(tf_output)\n",
        "  tf_prediction = tf.nn.sigmoid(tf_output).numpy()[0]\n",
        "  for prediction in tf_prediction:\n",
        "    print(prediction)\n",
        "  print(\"======================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l85Jjz-rJeBh",
        "outputId": "122ed732-46b3-4542-95bf-5f1fd3b9f2f4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 145ms/step\n",
            "make a call to rohit\n",
            "[[ 3.832683 -1.590358 -3.149823]]\n",
            "0.9788074\n",
            "0.16933352\n",
            "0.041098256\n",
            "======================\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "please text rohit\n",
            "[[-2.0426817  3.9051764 -3.068287 ]]\n",
            "0.11479395\n",
            "0.98026013\n",
            "0.044434506\n",
            "======================\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "get card details\n",
            "[[ 2.6885598   0.17730501 -3.756939  ]]\n",
            "0.9363482\n",
            "0.5442105\n",
            "0.02282211\n",
            "======================\n",
            "1/1 [==============================] - 0s 135ms/step\n",
            "connect\n",
            "[[ 1.9757013  0.6664451 -3.4063187]]\n",
            "0.87822217\n",
            "0.6607067\n",
            "0.032098573\n",
            "======================\n",
            "1/1 [==============================] - 0s 171ms/step\n",
            "send an email to rohit\n",
            "[[ 0.417647   2.5967636 -4.0802903]]\n",
            "0.6029201\n",
            "0.930653\n",
            "0.01662161\n",
            "======================\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "help\n",
            "[[ 2.3715224   0.49485078 -3.6090202 ]]\n",
            "0.9146298\n",
            "0.6212484\n",
            "0.026364457\n",
            "======================\n",
            "1/1 [==============================] - 0s 147ms/step\n",
            "call and chat\n",
            "[[-2.0949383  3.8443038 -2.947707 ]]\n",
            "0.10958976\n",
            "0.9790471\n",
            "0.049845003\n",
            "======================\n",
            "1/1 [==============================] - 0s 144ms/step\n",
            "chat and call\n",
            "[[-2.1342447  3.8343558 -2.8786938]]\n",
            "0.1058127\n",
            "0.9788421\n",
            "0.05321691\n",
            "======================\n",
            "1/1 [==============================] - 0s 150ms/step\n",
            "email someone\n",
            "[[ 0.97738916  2.1754687  -4.200155  ]]\n",
            "0.72658986\n",
            "0.89802486\n",
            "0.014771778\n",
            "======================\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "get time from india\n",
            "[[-2.3911498 -2.242928   3.7520523]]\n",
            "0.08385007\n",
            "0.09596122\n",
            "0.97706866\n",
            "======================\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "call rohit\n",
            "[[ 3.8689427 -1.3471696 -3.4220943]]\n",
            "0.97954667\n",
            "0.20633349\n",
            "0.03161205\n",
            "======================\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "call and chat\n",
            "[[-2.0949383  3.8443038 -2.947707 ]]\n",
            "0.10958976\n",
            "0.9790471\n",
            "0.049845003\n",
            "======================\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "chat and call\n",
            "[[-2.1342447  3.8343558 -2.8786938]]\n",
            "0.1058127\n",
            "0.9788421\n",
            "0.05321691\n",
            "======================\n",
            "1/1 [==============================] - 0s 144ms/step\n",
            "help\n",
            "[[ 2.3715224   0.49485078 -3.6090202 ]]\n",
            "0.9146298\n",
            "0.6212484\n",
            "0.026364457\n",
            "======================\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "connect with rohit\n",
            "[[ 1.8565453  0.704509  -3.2989504]]\n",
            "0.8648938\n",
            "0.6691867\n",
            "0.035607215\n",
            "======================\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "dial rohit\n",
            "[[ 1.8219088  0.7017423 -3.243301 ]]\n",
            "0.860795\n",
            "0.668574\n",
            "0.037568357\n",
            "======================\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "texting rohit\n",
            "[[-2.0629702  3.882003  -3.007935 ]]\n",
            "0.11274837\n",
            "0.97980666\n",
            "0.04706868\n",
            "======================\n",
            "1/1 [==============================] - 0s 209ms/step\n",
            "make a call and chat\n",
            "[[-2.018806   3.8390172 -3.0036252]]\n",
            "0.11724252\n",
            "0.9789384\n",
            "0.047262367\n",
            "======================\n",
            "1/1 [==============================] - 0s 140ms/step\n",
            "connect me with helpdesk\n",
            "[[ 1.9292692   0.71966785 -3.421395  ]]\n",
            "0.8731685\n",
            "0.67253387\n",
            "0.031633466\n",
            "======================\n",
            "1/1 [==============================] - 0s 172ms/step\n",
            "onboard me\n",
            "[[ 2.2691517   0.66970176 -3.6814897 ]]\n",
            "0.90628976\n",
            "0.6614364\n",
            "0.024566704\n",
            "======================\n"
          ]
        }
      ]
    }
  ]
}